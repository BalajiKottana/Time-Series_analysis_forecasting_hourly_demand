{"cells":[{"cell_type":"code","source":"import pandas as _hex_pandas\nimport datetime as _hex_datetime\nimport json as _hex_json","execution_count":null,"metadata":{},"outputs":[]},{"cell_type":"code","source":"hex_scheduled = _hex_json.loads(\"false\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_user_email = _hex_json.loads(\"\\\"example-user@example.com\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_run_context = _hex_json.loads(\"\\\"logic\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_timezone = _hex_json.loads(\"\\\"UTC\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_project_id = _hex_json.loads(\"\\\"712f741a-81ce-408e-9778-436c286f2be6\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_color_palette = _hex_json.loads(\"[\\\"#4C78A8\\\",\\\"#F58518\\\",\\\"#E45756\\\",\\\"#72B7B2\\\",\\\"#54A24B\\\",\\\"#EECA3B\\\",\\\"#B279A2\\\",\\\"#FF9DA6\\\",\\\"#9D755D\\\",\\\"#BAB0AC\\\"]\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":"# Setup\nInstall required packages and make sure all the libraries we need have been imported.","metadata":{}},{"cell_type":"code","source":"install = _hex_json.loads(\"false\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if install:\n    !pip install mockseries\n    !pip install --upgrade xgboost\nelse:\n    print(\"Click the button to install the required packages\")","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Requirement already satisfied: mockseries in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages (0.1.4)\nRequirement already satisfied: scipy==1.5.4 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages (from mockseries) (1.5.4)\nRequirement already satisfied: matplotlib==3.3.4 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages (from mockseries) (3.3.4)\nRequirement already satisfied: numpy==1.19.5 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages (from mockseries) (1.19.5)\nRequirement already satisfied: kiwisolver>=1.0.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages (from matplotlib==3.3.4->mockseries) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages (from matplotlib==3.3.4->mockseries) (0.10.0)\nRequirement already satisfied: pillow>=6.2.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages (from matplotlib==3.3.4->mockseries) (9.1.1)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages (from matplotlib==3.3.4->mockseries) (2.4.7)\nRequirement already satisfied: python-dateutil>=2.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages (from matplotlib==3.3.4->mockseries) (2.8.2)\nRequirement already satisfied: six in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages (from cycler>=0.10->matplotlib==3.3.4->mockseries) (1.15.0)\nRequirement already satisfied: xgboost in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages (1.7.4)\nRequirement already satisfied: numpy in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages (from xgboost) (1.19.5)\nRequirement already satisfied: scipy in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages (from xgboost) (1.5.4)\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"# Mock Data\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom mockseries.trend import LinearTrend\nfrom mockseries.seasonality import SinusoidalSeasonality\nfrom mockseries.noise import RedNoise\nfrom mockseries.utils import plot_timeseries, write_csv\nfrom datetime import datetime, date, timedelta\nfrom mockseries.utils import datetime_range\nfrom pandas.tseries.holiday import USFederalHolidayCalendar\nimport numpy as np\nimport random\n\n## Snowpark \nimport snowflake.snowpark\nfrom snowflake.snowpark.session import Session\nfrom snowflake.snowpark import functions as F\nfrom snowflake.snowpark.functions import col\nfrom snowflake.snowpark.types import StringType, DateType, TimestampType, IntegerType, StructType, StructField, FloatType\nfrom snowflake.snowpark.functions import dateadd, current_date\nfrom snowflake.snowpark.functions import udtf\n\n# Model Deployment\nfrom time import time\nimport sys, string, io, os, math\nimport zipfile, json, pickle\nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Establish Secure Connection to Snowflake\nAdd the schema to use throughout this project to the snowpark session connection. This ensures that data is always written to the correct location.","metadata":{}},{"cell_type":"code","source":"import hextoolkit\nhex_snowflake_conn = hextoolkit.get_data_connection('Snowflake')\nsession = hex_snowflake_conn.get_snowpark_session()\nsession.use_schema(\"PC_HEX_DB.PUBLIC\")\nsession.use_database(database=\"PC_HEX_DB\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating the data\n\n","metadata":{}},{"cell_type":"code","source":"class Dataset:\n    ''' Used to generate the data used for forecasting '''\n    def __init__(self):\n        trend = LinearTrend(coefficient=0.025, time_unit=timedelta(days=4), flat_base=100)\n        seasonality = SinusoidalSeasonality(\n            amplitude=20, period=timedelta(days=7)\n        ) + SinusoidalSeasonality(amplitude=4, period=timedelta(days=1))\n        noise = RedNoise(mean=0, std=3, correlation=0.5)\n        timeseries = trend + seasonality + noise\n\n        self.time_points = datetime_range(\n        granularity=timedelta(hours=1),\n        start_time=datetime(2018, 6, 16),\n        end_time=datetime.today())\n        self.ts_values = timeseries.generate(time_points=self.time_points)\n        self.data = None\n        self.dataset = None\n        self.calendar = None\n\n    def plot(self):\n        plot_timeseries(self.time_points, self.ts_values)\n\n    def _create_dataframe(self):\n        df = pd.DataFrame({\"time_points\":self.time_points,\"ts_values\":self.ts_values})\n        df['hour'] = df['time_points'].dt.hour\n        df['date'] = df['time_points'].dt.date\n        df['dayofweek'] = df['time_points'].dt.weekday\n\n        df = df[df['hour'].between(7,22)]\n\n        df['weekday'] = np.where((df['dayofweek']>= 1) & (df['dayofweek']<= 4), 1, 0)\n        df['weekend'] = np.where((df['dayofweek']>= 5) & (df['dayofweek']<= 6), 1, 0)\n        df['sunday'] = np.where(df['dayofweek']== 0 , 1, 0)\n        df['breakfast'] = np.where((df['hour']>= 7) & (df['hour']<= 10), 1, 0)\n        df['lunch'] = np.where((df['hour']>= 11) & (df['hour']<= 13), 1, 0)\n        df['break'] = np.where((df['hour']>= 14) & (df['hour']<= 15), 1, 0)\n        df['dinner'] = np.where((df['hour']>= 16) & (df['hour']<= 20), 1, 0)\n        df['close'] = np.where(df['hour']>= 21, 1, 0)\n        self.data = df\n\n    def _create_date_table(self, start='2018-01-01', end='2025-12-31'):\n        df = pd.DataFrame({\"CALENDAR_DATE\": pd.date_range(start, end)})\n        df[\"CALENDAR_WEEK_DAY_NBR\"] = df.CALENDAR_DATE.dt.dayofweek\n        df[\"CALENDAR_MTH_DAY_NBR\"] = df.CALENDAR_DATE.dt.day\n        df[\"CALENDAR_MTH\"] = df.CALENDAR_DATE.dt.month\n        df[\"CALENDAR_YEAR\"] = df.CALENDAR_DATE.dt.year\n        return df\n    \n    def _random_traffic(self, r):\n        if r[\"close\"] == 1:\n            return random.uniform(0,.1)\n        elif (r[\"weekday\"] == 1 and r[\"break\"] == 1) or (r[\"weekday\"] == 1 and r[\"breakfast\"] == 1):\n            return random.uniform(.15,.2)\n        elif (r[\"weekday\"] == 1 and r[\"dinner\"] == 1) or (r[\"weekend\"] == 1 and r[\"break\"] == 1):\n            return random.uniform(.25,.35)\n        elif (r[\"sunday\"] == 1) and (r[\"dinner\"] == 1):\n            return random.uniform(.4,.5)\n        elif (r[\"weekend\"] == 1 and r[\"breakfast\"] == 1) or (r[\"weekend\"] == 1 and r[\"dinner\"] == 1) or (r[\"weekday\"] == 1 and r[\"lunch\"] == 1) or (r[\"sunday\"] == 1 and r[\"break\"] == 1):\n            return random.uniform(.52,.65)\n        elif (r[\"sunday\"] == 1 and r[\"breakfast\"] == 1) or (r[\"weekend\"] == 1 and r[\"lunch\"] == 1):\n            return random.uniform(.70,.8)\n        elif (r[\"sunday\"] == 1 and r[\"lunch\"] == 1):\n            return random.uniform(.95,1)\n        else:\n            return 0\n\n    def create_traffic_table(self):\n        ''' Run this function to simulate the hourly traffic which is returned as a snowflake dataframe'''\n\n        print('Creating Initial Dataframe...', end = \" \")\n        self._create_dataframe()\n        print(\"Complete!\")\n\n        print('Simulating restaurant traffic... (about a 3 min wait)', end = ' ')\n        dfs = []\n        # takes abt 3 min to run\n        for i in range (1,201):\n            _ = self.data.copy()\n            _['store_id'] = i\n            _['college_town'] = np.random.randint(0,2)\n            _[\"rest_shift\"] = self.data.apply(self._random_traffic, axis = 1)\n            dfs.append(_)\n\n        self.data = pd.concat(dfs)\n        print(\"Complete!\")\n    \n        print(\"Adding US calendar Holidays...\", end = \" \")\n        calendar = USFederalHolidayCalendar()\n        holiday_df = (\n            pd.DataFrame(\n                calendar.holidays(start=min(self.data[\"date\"]), end=max(self.data[\"date\"]), return_name=True)\n            )\n            .reset_index()\n            .rename(columns={\"index\": \"date\", 0: \"holiday_name\"})\n        )\n\n        holiday_df['date'] = holiday_df['date'].dt.date\n        self.data = self.data.merge(holiday_df, on = 'date', how = 'left')\n        self.data['hourly_traffic'] = self.data.ts_values * self.data.rest_shift\n        print(\"Complete!\")\n\n        print(\"Creating master dataset...\", end = \" \")\n        final = self.data[['time_points', 'hourly_traffic','holiday_name','store_id','college_town']]\n        final['hourly_traffic'] = pd.to_numeric(final['hourly_traffic'])\n        final['hourly_traffic'] = final['hourly_traffic'].astype(float)\n        final['hourly_traffic'] = final['hourly_traffic'].round()\n        final['hourly_traffic'] = final['hourly_traffic'].astype(int)\n        final = final.rename(columns={\"time_points\": \"TIME_POINTS\", \"hourly_traffic\": \"HOURLY_TRAFFIC\",\"holiday_name\": \"HOLIDAY_NAME\",\"store_id\": \"STORE_ID\",\"college_town\":\"COLLEGE_TOWN\"})\n        self.dataset = final  \n        print(\"Master dataset created!\\nWrite this dataframe back into your Snowflake database.\")\n        return self.dataset\n\n    def create_calendar_table(self, session):\n        print(\"Creating calendar...\", end = \" \")\n        calendar_df = self._create_date_table()\n\n        calendar = USFederalHolidayCalendar()\n        holiday_df = (\n            pd.DataFrame(\n                calendar.holidays(start='2018-01-01', end='2025-12-31', return_name=True)\n            )\n            .reset_index()\n            .rename(columns={\"index\": \"date\", 0: \"holiday_name\"})\n        )\n\n        holiday_df['date'] = holiday_df['date'].dt.date\n        calendar_df['CALENDAR_DATE'] = calendar_df['CALENDAR_DATE'].dt.date\n        calendar_final = calendar_df.merge(holiday_df, left_on='CALENDAR_DATE', right_on='date', how = 'left')\n        calendar_final = calendar_final.rename(columns={\"holiday_name\":\"HOLIDAY_NAME\"})\n        calendar_final_snow_df = session.create_dataframe(calendar_final).select('CALENDAR_DATE','CALENDAR_WEEK_DAY_NBR','CALENDAR_MTH_DAY_NBR','CALENDAR_MTH','CALENDAR_YEAR','HOLIDAY_NAME')\n        calendar_final_snow_df = calendar_final_snow_df.select(\n            col(\"CALENDAR_DATE\"),\n            col(\"CALENDAR_WEEK_DAY_NBR\").cast(StringType()).alias(\"CALENDAR_WEEK_DAY_NBR\"),\n            col(\"CALENDAR_MTH_DAY_NBR\").cast(StringType()).alias(\"CALENDAR_MTH_DAY_NBR\"),\n            col(\"CALENDAR_MTH\").cast(StringType()).alias(\"CALENDAR_MTH\"),\n            col(\"CALENDAR_YEAR\").cast(StringType()).alias(\"CALENDAR_YEAR\"),\n            col(\"HOLIDAY_NAME\"),\n        )\n        self.calendar = calendar_final_snow_df.toPandas()\n        print(\"Complete!\")\n\n        return self.calendar","metadata":{},"execution_count":null,"outputs":[{"data":{"application/vnd.hex.scopeerror+json":"{\"message\": \"002003 (42S02): SQL compilation error:\\nObject 'HOURLY_TRAFFIC' does not exist or not authorized.\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"/python-kernel-startup/python_kernel_startup/hex_scope.py\\\", line 201, in _hex_get_scope\\n    item = _hex_get_scope_item(x)\\n  File \\\"/python-kernel-startup/python_kernel_startup/hex_scope.py\\\", line 100, in _hex_get_scope_item\\n    scope_item[\\\"displayValue\\\"] = \\\", \\\".join(value.columns)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/dataframe.py\\\", line 866, in columns\\n    return self.schema.names\\n  File \\\"/usr/local/lib/python3.8/functools.py\\\", line 967, in __get__\\n    val = self.func(instance)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/dataframe.py\\\", line 3403, in schema\\n    return StructType._from_attributes(self._plan.attributes)\\n  File \\\"/usr/local/lib/python3.8/functools.py\\\", line 967, in __get__\\n    val = self.func(instance)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py\\\", line 213, in attributes\\n    output = analyze_attributes(self.schema_query, self.session)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/schema_utils.py\\\", line 81, in analyze_attributes\\n    return session._get_result_attributes(sql)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/session.py\\\", line 1144, in _get_result_attributes\\n    return self._conn.get_result_attributes(query)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py\\\", line 156, in wrap\\n    raise ne.with_traceback(tb) from None\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py\\\", line 89, in wrap\\n    return func(*args, **kwargs)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py\\\", line 194, in get_result_attributes\\n    return convert_result_meta_to_attribute(self._cursor.describe(query))\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/cursor.py\\\", line 818, in describe\\n    self.execute(*args, **kwargs)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/cursor.py\\\", line 796, in execute\\n    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/errors.py\\\", line 275, in errorhandler_wrapper\\n    handed_over = Error.hand_to_other_handler(\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/errors.py\\\", line 330, in hand_to_other_handler\\n    cursor.errorhandler(connection, cursor, error_class, error_value)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/errors.py\\\", line 209, in default_errorhandler\\n    raise error_class(\\nsnowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01aacb59-0000-13d8-0000-00005205e09d: 002003 (42S02): SQL compilation error:\\nObject 'HOURLY_TRAFFIC' does not exist or not authorized.\\n\"}","text/plain":"<python_kernel_startup.hex_scope._hex_ScopeError at 0x7fd8ce4cfdc0>"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"# create an instance of the dataset class so that we can get our hourly traffic dataset\ndataset = Dataset()","metadata":{},"execution_count":null,"outputs":[{"data":{"application/vnd.hex.scopeerror+json":"{\"message\": \"002003 (42S02): SQL compilation error:\\nObject 'HOURLY_TRAFFIC' does not exist or not authorized.\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"/python-kernel-startup/python_kernel_startup/hex_scope.py\\\", line 201, in _hex_get_scope\\n    item = _hex_get_scope_item(x)\\n  File \\\"/python-kernel-startup/python_kernel_startup/hex_scope.py\\\", line 100, in _hex_get_scope_item\\n    scope_item[\\\"displayValue\\\"] = \\\", \\\".join(value.columns)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/dataframe.py\\\", line 866, in columns\\n    return self.schema.names\\n  File \\\"/usr/local/lib/python3.8/functools.py\\\", line 967, in __get__\\n    val = self.func(instance)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/dataframe.py\\\", line 3403, in schema\\n    return StructType._from_attributes(self._plan.attributes)\\n  File \\\"/usr/local/lib/python3.8/functools.py\\\", line 967, in __get__\\n    val = self.func(instance)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py\\\", line 213, in attributes\\n    output = analyze_attributes(self.schema_query, self.session)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/schema_utils.py\\\", line 81, in analyze_attributes\\n    return session._get_result_attributes(sql)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/session.py\\\", line 1144, in _get_result_attributes\\n    return self._conn.get_result_attributes(query)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py\\\", line 156, in wrap\\n    raise ne.with_traceback(tb) from None\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py\\\", line 89, in wrap\\n    return func(*args, **kwargs)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py\\\", line 194, in get_result_attributes\\n    return convert_result_meta_to_attribute(self._cursor.describe(query))\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/cursor.py\\\", line 818, in describe\\n    self.execute(*args, **kwargs)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/cursor.py\\\", line 796, in execute\\n    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/errors.py\\\", line 275, in errorhandler_wrapper\\n    handed_over = Error.hand_to_other_handler(\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/errors.py\\\", line 330, in hand_to_other_handler\\n    cursor.errorhandler(connection, cursor, error_class, error_value)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/errors.py\\\", line 209, in default_errorhandler\\n    raise error_class(\\nsnowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01aacb5f-0000-13d8-0000-00005205e0d1: 002003 (42S02): SQL compilation error:\\nObject 'HOURLY_TRAFFIC' does not exist or not authorized.\\n\"}","text/plain":"<python_kernel_startup.hex_scope._hex_ScopeError at 0x7fd58b191f40>"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"# We can get a pandas dataframe by calling this function, which generates the data for us\ntraffic = dataset.create_traffic_table()","metadata":{},"execution_count":null,"outputs":[{"data":{"application/vnd.hex.scopeerror+json":"{\"message\": \"002003 (42S02): SQL compilation error:\\nObject 'HOURLY_TRAFFIC' does not exist or not authorized.\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"/python-kernel-startup/python_kernel_startup/hex_scope.py\\\", line 201, in _hex_get_scope\\n    item = _hex_get_scope_item(x)\\n  File \\\"/python-kernel-startup/python_kernel_startup/hex_scope.py\\\", line 100, in _hex_get_scope_item\\n    scope_item[\\\"displayValue\\\"] = \\\", \\\".join(value.columns)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/dataframe.py\\\", line 866, in columns\\n    return self.schema.names\\n  File \\\"/usr/local/lib/python3.8/functools.py\\\", line 967, in __get__\\n    val = self.func(instance)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/dataframe.py\\\", line 3403, in schema\\n    return StructType._from_attributes(self._plan.attributes)\\n  File \\\"/usr/local/lib/python3.8/functools.py\\\", line 967, in __get__\\n    val = self.func(instance)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py\\\", line 213, in attributes\\n    output = analyze_attributes(self.schema_query, self.session)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/schema_utils.py\\\", line 81, in analyze_attributes\\n    return session._get_result_attributes(sql)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/session.py\\\", line 1144, in _get_result_attributes\\n    return self._conn.get_result_attributes(query)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py\\\", line 156, in wrap\\n    raise ne.with_traceback(tb) from None\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py\\\", line 89, in wrap\\n    return func(*args, **kwargs)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py\\\", line 194, in get_result_attributes\\n    return convert_result_meta_to_attribute(self._cursor.describe(query))\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/cursor.py\\\", line 818, in describe\\n    self.execute(*args, **kwargs)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/cursor.py\\\", line 796, in execute\\n    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/errors.py\\\", line 275, in errorhandler_wrapper\\n    handed_over = Error.hand_to_other_handler(\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/errors.py\\\", line 330, in hand_to_other_handler\\n    cursor.errorhandler(connection, cursor, error_class, error_value)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/errors.py\\\", line 209, in default_errorhandler\\n    raise error_class(\\nsnowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01aacb62-0000-13d8-0000-00005205e0d5: 002003 (42S02): SQL compilation error:\\nObject 'HOURLY_TRAFFIC' does not exist or not authorized.\\n\"}","text/plain":"<python_kernel_startup.hex_scope._hex_ScopeError at 0x7fd82b0e59d0>"},"execution_count":null,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":"Creating Initial Dataframe... Complete!\nSimulating restaurant traffic... (about a 3 min wait) Complete!\nAdding US calendar Holidays... Complete!\nCreating master dataset... Master dataset created!\nWrite this dataframe back into your Snowflake database.\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"cal = dataset.create_calendar_table(session)","metadata":{},"execution_count":null,"outputs":[{"data":{"application/vnd.hex.scopeerror+json":"{\"message\": \"002003 (42S02): SQL compilation error:\\nObject 'HOURLY_TRAFFIC' does not exist or not authorized.\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"/python-kernel-startup/python_kernel_startup/hex_scope.py\\\", line 201, in _hex_get_scope\\n    item = _hex_get_scope_item(x)\\n  File \\\"/python-kernel-startup/python_kernel_startup/hex_scope.py\\\", line 100, in _hex_get_scope_item\\n    scope_item[\\\"displayValue\\\"] = \\\", \\\".join(value.columns)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/dataframe.py\\\", line 866, in columns\\n    return self.schema.names\\n  File \\\"/usr/local/lib/python3.8/functools.py\\\", line 967, in __get__\\n    val = self.func(instance)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/dataframe.py\\\", line 3403, in schema\\n    return StructType._from_attributes(self._plan.attributes)\\n  File \\\"/usr/local/lib/python3.8/functools.py\\\", line 967, in __get__\\n    val = self.func(instance)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py\\\", line 213, in attributes\\n    output = analyze_attributes(self.schema_query, self.session)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/schema_utils.py\\\", line 81, in analyze_attributes\\n    return session._get_result_attributes(sql)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/session.py\\\", line 1144, in _get_result_attributes\\n    return self._conn.get_result_attributes(query)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py\\\", line 156, in wrap\\n    raise ne.with_traceback(tb) from None\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py\\\", line 89, in wrap\\n    return func(*args, **kwargs)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py\\\", line 194, in get_result_attributes\\n    return convert_result_meta_to_attribute(self._cursor.describe(query))\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/cursor.py\\\", line 818, in describe\\n    self.execute(*args, **kwargs)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/cursor.py\\\", line 796, in execute\\n    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/errors.py\\\", line 275, in errorhandler_wrapper\\n    handed_over = Error.hand_to_other_handler(\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/errors.py\\\", line 330, in hand_to_other_handler\\n    cursor.errorhandler(connection, cursor, error_class, error_value)\\n  File \\\"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.8/lib/python3.8/site-packages/snowflake/connector/errors.py\\\", line 209, in default_errorhandler\\n    raise error_class(\\nsnowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01aacb65-0000-13d8-0000-00005205e0fd: 002003 (42S02): SQL compilation error:\\nObject 'HOURLY_TRAFFIC' does not exist or not authorized.\\n\"}","text/plain":"<python_kernel_startup.hex_scope._hex_ScopeError at 0x7fd8407381f0>"},"execution_count":null,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":"Creating calendar... Complete!\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","source":"## Write data back to database\n\n","metadata":{}},{"cell_type":"code","source":"# if hex_run_context in [\"logic\"]:\n#     import hextoolkit\n#     hex_data_connection = hextoolkit.get_data_connection(\"Snowflake\")\n#     writeback_metadata = hex_data_connection.write_dataframe(df=traffic, database=\"PC_HEX_DB\", schema=\"PUBLIC\", table=\"HOURLY_TRAFFIC\", overwrite=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if hex_run_context in [\"logic\"]:\n#     import hextoolkit\n#     hex_data_connection = hextoolkit.get_data_connection(\"Snowflake\")\n#     writeback_metadata = hex_data_connection.write_dataframe(df=cal, database=\"PC_HEX_DB\", schema=\"PUBLIC\", table=\"CALENDAR_INFO\", overwrite=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Add stage for UDFs and Stored Procs\nsession.sql('''\ncreate stage if not exists pymodels\n''').collect()","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"[Row(status='PYMODELS already exists, statement succeeded.')]"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","source":"# Explore Historical Data\n\nLet's look at the historical **HOURLY_TRAFFIC** and **CALENDAR_INFO** tables from the stores.","metadata":{}},{"cell_type":"code","source":"store_hourly_info_df = session.table('HOURLY_TRAFFIC')\nstore_hourly_info_df.limit(10).toPandas()","metadata":{},"execution_count":null,"outputs":[{"data":{"application/vnd.hex.export+parquet":{"success":true,"exportKey":"exports/fe9ded7a-279f-4490-9d80-55120ff23496"},"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TIME_POINTS</th>\n      <th>HOURLY_TRAFFIC</th>\n      <th>HOLIDAY_NAME</th>\n      <th>STORE_ID</th>\n      <th>COLLEGE_TOWN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-06-16 07:00:00</td>\n      <td>70</td>\n      <td>None</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-06-16 08:00:00</td>\n      <td>62</td>\n      <td>None</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-06-16 09:00:00</td>\n      <td>62</td>\n      <td>None</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-06-16 10:00:00</td>\n      <td>64</td>\n      <td>None</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-06-16 11:00:00</td>\n      <td>87</td>\n      <td>None</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2018-06-16 12:00:00</td>\n      <td>80</td>\n      <td>None</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2018-06-16 13:00:00</td>\n      <td>74</td>\n      <td>None</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2018-06-16 14:00:00</td>\n      <td>30</td>\n      <td>None</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2018-06-16 15:00:00</td>\n      <td>26</td>\n      <td>None</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2018-06-16 16:00:00</td>\n      <td>54</td>\n      <td>None</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"store_calendar_info_df = session.table('CALENDAR_INFO')\nstore_calendar_info_df.limit(10).toPandas()","metadata":{},"execution_count":null,"outputs":[{"data":{"application/vnd.hex.export+parquet":{"success":true,"exportKey":"exports/baf6381b-3559-4a7a-8276-97ea45d16e62"},"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CALENDAR_DATE</th>\n      <th>CALENDAR_WEEK_DAY_NBR</th>\n      <th>CALENDAR_MTH_DAY_NBR</th>\n      <th>CALENDAR_MTH</th>\n      <th>CALENDAR_YEAR</th>\n      <th>HOLIDAY_NAME</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-01-01</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2018</td>\n      <td>New Year's Day</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-01-02</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2018</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-01-03</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2018</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-01-04</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2018</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-01-05</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2018</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2018-01-06</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1</td>\n      <td>2018</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2018-01-07</td>\n      <td>6</td>\n      <td>7</td>\n      <td>1</td>\n      <td>2018</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2018-01-08</td>\n      <td>0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>2018</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2018-01-09</td>\n      <td>1</td>\n      <td>9</td>\n      <td>1</td>\n      <td>2018</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2018-01-10</td>\n      <td>2</td>\n      <td>10</td>\n      <td>1</td>\n      <td>2018</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","source":"# Feature Engineering and Data Pre-Processing Tasks\nWe're going to create a feature table with past historical data and future data to pass in to our XGBoost model.","metadata":{}},{"cell_type":"markdown","source":"### Create a dataframe with relevant historical data","metadata":{}},{"cell_type":"code","source":"## Extract date and hour from the time stamp in Hourly traffic\npast = store_hourly_info_df.select(\n    \"TIME_POINTS\",\n    col(\"TIME_POINTS\").cast(DateType()).alias(\"DATE\"),\n    F.hour(col(\"TIME_POINTS\")).alias(\"HOUR\"),\n    \"STORE_ID\",\n    \"COLLEGE_TOWN\",\n    \"HOURLY_TRAFFIC\",\n)\n\n\n## Join the Calendar info table to the Hourly traffic table\n## Filter hour between 7 and 22 since the restaraunts are only open from 7am -> 10pm\npast_final = (\n    past.join(\n        store_calendar_info_df,\n        (store_calendar_info_df.col(\"CALENDAR_DATE\") == past.col(\"DATE\")),\n        \"left\",\n    )\n    .select(\n        col(\"TIME_POINTS\"),\n        col(\"HOUR\"),\n        \"STORE_ID\",\n        \"COLLEGE_TOWN\",\n        \"CALENDAR_WEEK_DAY_NBR\",\n        \"CALENDAR_MTH_DAY_NBR\",\n        \"CALENDAR_MTH\",\n        \"CALENDAR_YEAR\",\n        \"HOLIDAY_NAME\",\n        \"HOURLY_TRAFFIC\",\n    )\n    .filter(col(\"HOUR\").between(7, 22))\n    .na.fill({\"HOLIDAY_NAME\": \"No Holiday\"})\n)\n\npast_final.limit(5).toPandas()","metadata":{},"execution_count":null,"outputs":[{"data":{"application/vnd.hex.export+parquet":{"success":true,"exportKey":"exports/b92012ae-9c9d-47c6-90b6-7756e3615768"},"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TIME_POINTS</th>\n      <th>HOUR</th>\n      <th>STORE_ID</th>\n      <th>COLLEGE_TOWN</th>\n      <th>CALENDAR_WEEK_DAY_NBR</th>\n      <th>CALENDAR_MTH_DAY_NBR</th>\n      <th>CALENDAR_MTH</th>\n      <th>CALENDAR_YEAR</th>\n      <th>HOLIDAY_NAME</th>\n      <th>HOURLY_TRAFFIC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-06-16 07:00:00</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>16</td>\n      <td>6</td>\n      <td>2018</td>\n      <td>No Holiday</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-06-16 08:00:00</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>16</td>\n      <td>6</td>\n      <td>2018</td>\n      <td>No Holiday</td>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-06-16 09:00:00</td>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>16</td>\n      <td>6</td>\n      <td>2018</td>\n      <td>No Holiday</td>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-06-16 10:00:00</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>16</td>\n      <td>6</td>\n      <td>2018</td>\n      <td>No Holiday</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-06-16 11:00:00</td>\n      <td>11</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>16</td>\n      <td>6</td>\n      <td>2018</td>\n      <td>No Holiday</td>\n      <td>87</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","source":"### Generate store info with a empty hourly traffic for the next four weeks for forecasting ","metadata":{}},{"cell_type":"code","source":"## Create a column that has the next 672 hours (28 days) in date time format.\ndf_date = session.range(672).select(dateadd(\"HOUR\", \"ID\", current_date()).as_(\"DATE\"))\n\ndf_date = df_date.with_column(\"HOUR\",F.hour(df_date[\"DATE\"]))\n\ndf_date = df_date.select(F.to_date(df_date[\"DATE\"]).as_(\"DATE\"),'HOUR').filter(col('HOUR').between(7,22))\n\n ## Cross join to make sure each store gets a value for the next 4 weeks\ndf_store = session.table('HOURLY_TRAFFIC').select(col('STORE_ID').cast(\"string\").alias(\"STORE_ID\"),col('COLLEGE_TOWN').cast(\"string\").alias(\"COLLEGE_TOWN\")).distinct()\nstores = df_date.cross_join(df_store)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Add in Calendar Information to create the final future table\nfuture_cal = session.table('CALENDAR_INFO')\\\n    .select('CALENDAR_DATE',\\\n            'CALENDAR_WEEK_DAY_NBR',\\\n            'CALENDAR_MTH_DAY_NBR',\\\n            'CALENDAR_MTH',\\\n            'CALENDAR_YEAR',\\\n            'HOLIDAY_NAME').\\\n    filter((F.col('CALENDAR_DATE') >= F.current_date())\\\n                                          & (F.col('CALENDAR_DATE')  <= F.current_date()+28))\n\nfuture_cal = future_cal.na.fill({\"HOLIDAY_NAME\": 'No Holiday'})\n\n## Join store info and calendar data\nfuture_df = stores.join(future_cal, stores.col(\"DATE\") == future_cal.col(\"CALENDAR_DATE\"),\"right\")\nfuture_df = future_df.drop('CALENDAR_DATE')\n\nfuture_df = future_df.withColumn(\"DATE_HOUR\", F.to_timestamp(F.dateadd(\"hour\",col(\"HOUR\"),col(\"DATE\"))))\nfuture_df = future_df.drop('DATE')\n\nfuture_df = future_df.withColumn('HOURLY_TRAFFIC', F.lit(0))\n\nfuture_df = future_df.select('DATE_HOUR',\\\n                'HOUR',\\\n                'STORE_ID',\\\n                'COLLEGE_TOWN',\\\n                'CALENDAR_WEEK_DAY_NBR',\\\n                'CALENDAR_MTH_DAY_NBR',\\\n                'CALENDAR_MTH',\\\n                'CALENDAR_YEAR',\\\n                'HOLIDAY_NAME',\\\n                'HOURLY_TRAFFIC')\n\nfuture_df.limit().toPandas()","metadata":{},"execution_count":null,"outputs":[{"data":{"application/vnd.hex.export+parquet":{"success":true,"exportKey":"exports/ece0c6c9-6fce-448f-b038-b9fde5f29faf"},"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DATE_HOUR</th>\n      <th>HOUR</th>\n      <th>STORE_ID</th>\n      <th>COLLEGE_TOWN</th>\n      <th>CALENDAR_WEEK_DAY_NBR</th>\n      <th>CALENDAR_MTH_DAY_NBR</th>\n      <th>CALENDAR_MTH</th>\n      <th>CALENDAR_YEAR</th>\n      <th>HOLIDAY_NAME</th>\n      <th>HOURLY_TRAFFIC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-03-07 07:00:00</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2023</td>\n      <td>No Holiday</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023-03-07 07:00:00</td>\n      <td>7</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2023</td>\n      <td>No Holiday</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023-03-07 07:00:00</td>\n      <td>7</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2023</td>\n      <td>No Holiday</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-03-07 07:00:00</td>\n      <td>7</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2023</td>\n      <td>No Holiday</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023-03-07 07:00:00</td>\n      <td>7</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2023</td>\n      <td>No Holiday</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>2023-03-07 07:00:00</td>\n      <td>7</td>\n      <td>86</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2023</td>\n      <td>No Holiday</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>2023-03-07 07:00:00</td>\n      <td>7</td>\n      <td>90</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2023</td>\n      <td>No Holiday</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>2023-03-07 07:00:00</td>\n      <td>7</td>\n      <td>92</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2023</td>\n      <td>No Holiday</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>2023-03-07 07:00:00</td>\n      <td>7</td>\n      <td>96</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2023</td>\n      <td>No Holiday</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>2023-03-07 07:00:00</td>\n      <td>7</td>\n      <td>98</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2023</td>\n      <td>No Holiday</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 10 columns</p>\n</div>"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","source":"### Save final features to a new table ","metadata":{}},{"cell_type":"code","source":" ## Union the historical and future tables together\nunionDF = past_final.union(future_df)\n    \n## Write the final features table to Snowflake \nunionDF.write.saveAsTable('MODEL_FEATURES', mode='overwrite', create_temp_table=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training & batch forecasts using a UDTFs. ","metadata":{}},{"cell_type":"code","source":"schema = StructType([\n     StructField(\"DATE\", DateType()),\n    StructField(\"HOUR_OF_DAY\", IntegerType()),\n    StructField(\"HOURLY_FORECAST\", FloatType())  \n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@udtf(output_schema = schema,\n     input_types = [TimestampType(), IntegerType(),IntegerType(),FloatType(),StringType(),StringType(),StringType(),StringType()],\n     name = \"store_forecast\", is_permanent=True, stage_location=\"@pymodels\",\n     packages=[\"pandas\",\"xgboost == 1.5.0\"], replace=True, session=session)\nclass forecast:\n    def __init__(self):\n        self.date_hour=[]\n        self.from_hour=[]\n        self.COLLEGE_TOWN=[]\n        self.DAYOFWEEK=[]\n        self.MONTH=[]\n        self.YEAR=[]\n        self.HOLIDAY_NAME=[]\n        self.HOURLY_TRAFFIC=[]\n    \n    def process(self, date_hour, HOURLY_TRAFFIC, from_hour, COLLEGE_TOWN, DAYOFWEEK, MONTH, YEAR, HOLIDAY_NAME):\n        self.date_hour.append(date_hour)\n        self.HOURLY_TRAFFIC.append(HOURLY_TRAFFIC)\n        self.from_hour.append(from_hour)\n        self.COLLEGE_TOWN.append(COLLEGE_TOWN)\n        self.DAYOFWEEK.append(DAYOFWEEK)\n        self.MONTH.append(MONTH)\n        self.YEAR.append(YEAR)\n        self.HOLIDAY_NAME.append(HOLIDAY_NAME)\n    \n    def end_partition(self):\n        df = pd.DataFrame(zip(self.date_hour, \n                              self.HOURLY_TRAFFIC, \n                              self.from_hour, \n                              self.COLLEGE_TOWN, \n                              self.DAYOFWEEK, \n                              self.MONTH, \n                              self.YEAR, \n                              self.HOLIDAY_NAME), \n                          columns = ['DATE_HOUR','HOURLY_TRAFFIC','HOUR','COLLEGE_TOWN','CALENDAR_WEEK_DAY_NBR',\n                                     'CALENDAR_MTH','CALENDAR_YEAR','HOLIDAY_NAME'])\n        \n        # set the time column as our index \n        df2 = df.set_index('DATE_HOUR') \n        df2.index = pd.to_datetime(df2.index)\n\n         # Converting features to categories for get_dummies\n        df2['CALENDAR_WEEK_DAY_NBR'] = df2['CALENDAR_WEEK_DAY_NBR'].astype(\"category\")\n        df2['CALENDAR_MTH'] = df2['CALENDAR_MTH'].astype(\"category\")\n        df2['CALENDAR_YEAR'] = df2['CALENDAR_YEAR'].astype(\"category\")\n        df2['HOUR'] = df2['HOUR'].astype(\"category\")\n        df2['HOLIDAY_NAME'] = df2['HOLIDAY_NAME'].astype(\"category\")\n        df2['COLLEGE_TOWN'] = df2['COLLEGE_TOWN'].astype(\"category\")\n\n        #Use get_dummies for categorical features\n        final = pd.get_dummies(data=df2, columns=['HOLIDAY_NAME', \n                                                  'COLLEGE_TOWN','CALENDAR_WEEK_DAY_NBR','CALENDAR_MTH','CALENDAR_YEAR','HOUR'])\n       \n        #do the train & forecast split\n        today = date.today()\n        yesterday = today - timedelta(days = 1)\n        fourweek = today + timedelta(days = 28)\n        tomorrow = today + timedelta(days = 1)\n\n        train = final[(final.index >= pd.to_datetime('16-Jun-2018')) & (final.index <= pd.to_datetime(yesterday))]\n        forecast = final[(final.index >= pd.to_datetime(tomorrow)) & (final.index <=pd.to_datetime(fourweek))]\n\n        X_train = train.drop('HOURLY_TRAFFIC', axis = 1)\n        y_train = train['HOURLY_TRAFFIC']\n\n        X_forecast = forecast.drop('HOURLY_TRAFFIC', axis = 1)\n        \n        #Use XGBoost regressor model\n        model = xgb.XGBRegressor(n_estimators=200,n_jobs=1)\n        model.fit(X_train, y_train,\n                verbose=False) \n        \n        forecast['PREDICTION'] = model.predict(X_forecast)\n\n        hours = forecast.index.hour\n        forecast = pd.concat([forecast, pd.DataFrame(hours, index=forecast.index)], axis = 1)\n        forecast = forecast[[\"DATE_HOUR\",\"PREDICTION\"]]\n        forecast = forecast.sort_index()\n        forecast.loc[forecast['PREDICTION'] < 0,'PREDICTION']=0\n        forecast['DATE'] = forecast.index.date\n        \n        # output prediction\n        for idx, row in forecast.iterrows():\n            DATE = row['DATE']\n            DATE_HOUR = row['DATE_HOUR']\n            PREDICTION = row['PREDICTION']\n            yield DATE, DATE_HOUR, PREDICTION","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"The version of package xgboost in the local environment is 1.7.1, which does not fit the criteria for the requirement xgboost == 1.5.0. Your UDF might not work when the package version is different between the server and your local environment\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","source":"## Call the UDTF on Snowpark Optimized WH to run models in prallel and get forecast","metadata":{}},{"cell_type":"code","source":"df = session.table(\"MODEL_FEATURES\")\nstore_forecast = F.table_function(\"store_forecast\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forecast = df.select(\n    df[\"STORE_ID\"],\n    (\n        store_forecast(\n            df[\"TIME_POINTS\"],\n            df[\"HOURLY_TRAFFIC\"],\n            df[\"HOUR\"],\n            df[\"COLLEGE_TOWN\"].cast(FloatType()),#.alias('COLLEGE_TOWN'),\n            df[\"CALENDAR_WEEK_DAY_NBR\"],\n            df[\"CALENDAR_MTH_DAY_NBR\"],\n            df[\"CALENDAR_YEAR\"],\n            df[\"HOLIDAY_NAME\"],\n        ).over(partition_by=df[\"STORE_ID\"])\n    ),\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forecast.limit(10).show()","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"----------------------------------------------------------------\n|\"STORE_ID\"  |\"DATE\"      |\"HOUR_OF_DAY\"  |\"HOURLY_FORECAST\"   |\n----------------------------------------------------------------\n|86.00000    |2023-03-08  |7              |18.91967010498047   |\n|86.00000    |2023-03-08  |8              |17.730106353759766  |\n|86.00000    |2023-03-08  |9              |18.50977325439453   |\n|86.00000    |2023-03-08  |10             |16.77593994140625   |\n|86.00000    |2023-03-08  |11             |58.48009490966797   |\n|86.00000    |2023-03-08  |12             |56.95584487915039   |\n|86.00000    |2023-03-08  |13             |56.55628204345703   |\n|86.00000    |2023-03-08  |14             |16.796043395996094  |\n|86.00000    |2023-03-08  |15             |15.834382057189941  |\n|86.00000    |2023-03-08  |16             |27.422399520874023  |\n----------------------------------------------------------------\n\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"# takes abt 7 minutes (on an x-small warehouse)\nforecast.write.saveAsTable('FOUR_WEEK_FORECAST', mode='overwrite', create_temp_table=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import jinja2\n# raw_query = \"\"\"\n#     select * from \"PC_HEX_DB\".\"PUBLIC\".\"FOUR_WEEK_FORECAST\"\n# \"\"\"\n# sql_query = jinja2.Template(raw_query).render(vars())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"date_hour = np.array(list(zip(dataframe_3['DATE'].astype('str'), dataframe_3[\"HOUR_OF_DAY\"].astype('str'))))\nfull_time = []\nfor date, hour in date_hour:\n    full_time.append(pd.to_datetime(f\"{date} {hour}:00\"))\n\ndataframe_3['time'] = full_time","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import altair\nchart_dataframe_3 = altair.Chart.from_json(\"\"\"\n{\n    \"width\": 500,\n    \"height\": 500,\n    \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n    \"layer\": [\n        {\n            \"data\": {\n                \"name\": \"layer00\"\n            },\n            \"mark\": {\n                \"type\": \"line\",\n                \"clip\": true,\n                \"tooltip\": true\n            },\n            \"encoding\": {\n                \"x\": {\n                    \"field\": \"time\",\n                    \"type\": \"temporal\",\n                    \"timeUnit\": \"yearmonthdatehours\"\n                },\n                \"y\": {\n                    \"field\": \"HOURLY_FORECAST\",\n                    \"type\": \"quantitative\"\n                }\n            }\n        }\n    ],\n    \"resolve\": {\n        \"scale\": {}\n    },\n    \"datasets\": {\n        \"layer00\": [\n            {\n                \"name\": \"dummy\",\n                \"value\": 0\n            }\n        ]\n    }\n}\n\"\"\")\nchart_dataframe_3.datasets.layer00 = dataframe_3.to_json(orient='records')\nchart_dataframe_3.display(actions=False)","metadata":{},"execution_count":null,"outputs":[]}],"metadata":{"orig_nbformat":4,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"hex_info":{"author":"Balaji Kottana","project_id":"712f741a-81ce-408e-9778-436c286f2be6","version":"import","exported_date":"Wed Mar 08 2023 00:02:12 GMT+0000 (Coordinated Universal Time)"}},"nbformat":4,"nbformat_minor":4}